{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Imran012x/butterfly/blob/main/1_CNN%2Btransfer_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# import zipfile\n",
        "# import os\n",
        "\n",
        "# with zipfile.ZipFile('data.zip', 'r') as zip_ref:\n",
        "#     zip_ref.extractall('')"
      ],
      "metadata": {
        "id": "JP345hvS1nk1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "import cv2\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "common_pic= os.listdir('/content/common/')\n",
        "print(common_pic[0:5])\n",
        "print(common_pic[-5:])\n",
        "\n",
        "\n",
        "painted_pic= os.listdir('/content/painted/')\n",
        "\n",
        "\n",
        "red_based_pic= os.listdir('/content/red_based/')\n",
        "\n",
        "\n",
        "red_spot_pic= os.listdir('/content/red_spot/')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rMyf2SoU2C0T",
        "outputId": "80002cb3-cad0-40f5-d5e9-55cd10c888bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['medium77.jpg', '13601_small.JPG.jpg', 'Delias20eucharis_1711145084_268153.jpg', 'square18.jpg', 'medium90.jpeg']\n",
            "['medium202.jpeg', 'medium20.jpg', 'medium187.jpeg', 'medium167.jpeg', 'medium337.jpeg']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print('Common  Jezebel_Delias eucharis images:', len(common_pic))\n",
        "print('Painted Jezebel_Delias hyparete images:', len(painted_pic))\n",
        "print('Red-Based  Jezebel_Delias pasithoe images:', len(red_based_pic))\n",
        "print('Red-Spot Jezebel_Delias descombesi images:', len(red_spot_pic))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cU6TyDxt2Hp2",
        "outputId": "faecfeff-7869-4a06-bbe0-1e0b1370194d"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Common  Jezebel_Delias eucharis images: 454\n",
            "Painted Jezebel_Delias hyparete images: 868\n",
            "Red-Based  Jezebel_Delias pasithoe images: 1089\n",
            "Red-Spot Jezebel_Delias descombesi images: 690\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create the labels\n",
        "# common_pic_labels = [0]*455\n",
        "# painted_pic_labels = [1]*869\n",
        "# red_based_pic_labels = [2]*1090\n",
        "# red_spot_pic_labels = [3]*690\n",
        "\n",
        "\n",
        "common_pic_labels = [0]*454\n",
        "painted_pic_labels = [1]*868\n",
        "red_based_pic_labels = [2]*1089\n",
        "red_spot_pic_labels = [3]*690\n",
        "\n",
        "\n",
        "print(common_pic_labels[0:5])\n",
        "\n",
        "print(painted_pic_labels[0:5])\n",
        "\n",
        "print(red_based_pic_labels[0:5])\n",
        "\n",
        "print(red_spot_pic_labels[0:5])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50rePefD2Km6",
        "outputId": "552bf728-c279-487c-aa82-735c10f8a96e"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1]\n",
            "[2, 2, 2, 2, 2]\n",
            "[3, 3, 3, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(common_pic_labels))\n",
        "print(len(painted_pic_labels))\n",
        "print(len(red_based_pic_labels))\n",
        "print(len(red_spot_pic_labels))\n",
        "\n",
        "\n",
        "labels = common_pic_labels + painted_pic_labels + red_based_pic_labels + red_spot_pic_labels\n",
        "\n",
        "print(len(labels))\n",
        "print(labels[0:5])\n",
        "print(labels[-5:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iwYTot_v1QTw",
        "outputId": "b3691623-eb35-454e-8e1a-d398df044038"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "454\n",
            "868\n",
            "1089\n",
            "690\n",
            "3101\n",
            "[0, 0, 0, 0, 0]\n",
            "[3, 3, 3, 3, 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Path to the directory containing images\n",
        "image_dir = \"/content/common/\"\n",
        "\n",
        "# List all files in the directory\n",
        "for file_name in os.listdir(image_dir):\n",
        "    file_path = os.path.join(image_dir, file_name)\n",
        "\n",
        "    # Check if it's a directory\n",
        "    if os.path.isdir(file_path):\n",
        "        print(f\"Directory found: {file_path}\")\n"
      ],
      "metadata": {
        "id": "Q-sG-8ca9pDc"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "# Path to the main directory\n",
        "main_dir = \"/content/common/\"\n",
        "\n",
        "# Check if the .ipynb_checkpoints directory exists and delete it\n",
        "checkpoint_dir = os.path.join(main_dir, \".ipynb_checkpoints\")\n",
        "\n",
        "if os.path.exists(checkpoint_dir) and os.path.isdir(checkpoint_dir):\n",
        "    shutil.rmtree(checkpoint_dir)\n",
        "    print(f\"Deleted directory: {checkpoint_dir}\")\n",
        "else:\n",
        "    print(\"Directory not found.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "88PGyFaG-C8U",
        "outputId": "aa421d9c-4547-4726-aa6f-af1e529f01ca"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Deleted directory: /content/common/.ipynb_checkpoints\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import os\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "# Parameters (set different numbers for each class)\n",
        "common_image_number = 617\n",
        "painted_image_number = 897\n",
        "red_based_image_number = 1154\n",
        "red_spot_image_number = 690\n",
        "\n",
        "\n",
        "# Initialize the list to store the images\n",
        "data = []\n",
        "\n",
        "def process_images(image_path, image_number):\n",
        "    image_labels = sorted(os.listdir(image_path))  # Ensure images are in order\n",
        "    random.shuffle(image_labels)  # Shuffle to get random ones\n",
        "    selected_images = []\n",
        "    for img_file in image_labels[:image_number]:\n",
        "        image = Image.open(os.path.join(image_path, img_file))\n",
        "        image = image.resize((224, 224))\n",
        "        image = image.convert('RGB')\n",
        "        image = np.array(image)\n",
        "        selected_images.append(image)\n",
        "    return selected_images\n",
        "\n",
        "# Process images for each category\n",
        "data.extend(process_images('/content/common/', common_image_number))\n",
        "data.extend(process_images('/content/painted/', painted_image_number))\n",
        "data.extend(process_images('/content/red_based/', red_based_image_number))\n",
        "data.extend(process_images('/content/red_spot/', red_spot_image_number))"
      ],
      "metadata": {
        "id": "6gu2Bfj02ht1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "outputId": "93ac1f98-c7e1-45b2-bae3-cc7cb4a2dc39"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IsADirectoryError",
          "evalue": "[Errno 21] Is a directory: '/content/common/.ipynb_checkpoints'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIsADirectoryError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-4616526310db>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;31m# Process images for each category\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/common/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcommon_image_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/painted/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpainted_image_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/red_based/'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mred_based_image_number\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-6-4616526310db>\u001b[0m in \u001b[0;36mprocess_images\u001b[0;34m(image_path, image_number)\u001b[0m\n\u001b[1;32m     19\u001b[0m     \u001b[0mselected_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mimg_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimage_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mimage_number\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m224\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m224\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3464\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3465\u001b[0;31m         \u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3466\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3467\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mIsADirectoryError\u001b[0m: [Errno 21] Is a directory: '/content/common/.ipynb_checkpoints'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to numpy array for easy processing\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Count the number of images in each class\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "\n",
        "# Print the number of images for each class\n",
        "class_counts = dict(zip(unique, counts))\n",
        "print(f\"Class counts: {class_counts}\")\n",
        "# converting image list and label list to numpy arrays\n",
        "\n",
        "X = np.array(data)\n",
        "Y = np.array(labels)\n",
        "print(X.shape)\n",
        "print(Y.shape)\n",
        "\n"
      ],
      "metadata": {
        "id": "FyNKmCny1UYk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=2)\n",
        "print(X.shape, X_train.shape, X_test.shape)\n",
        "# scaling the data\n",
        "\n",
        "X_train_scaled = X_train/255\n",
        "\n",
        "X_test_scaled = X_test/255\n",
        "\n",
        "X_train[0]"
      ],
      "metadata": {
        "id": "a_Auo6ip2l_g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Optuna-Hyper parameter Training"
      ],
      "metadata": {
        "id": "C4tpEFOX5BBr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, accuracy_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Define model creation function\n",
        "def create_model(learning_rate, num_filters, kernel_size):\n",
        "    input_shape = (224, 224, 3)\n",
        "    base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "    x = base_model.output\n",
        "    x = Conv2D(num_filters, (kernel_size, kernel_size), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = Conv2D(num_filters * 2, (kernel_size, kernel_size), activation='relu', padding='same')(x)\n",
        "    x = MaxPooling2D((2, 2))(x)\n",
        "    x = GlobalAveragePooling2D()(x)\n",
        "    x = Dense(256, activation='relu')(x)\n",
        "    output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "    model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "    for layer in base_model.layers:\n",
        "        layer.trainable = False\n",
        "\n",
        "    model.compile(optimizer=RMSprop(learning_rate=learning_rate),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Define Optuna objective function\n",
        "def objective(trial):\n",
        "    learning_rate = trial.suggest_loguniform('learning_rate', 1e-5, 1e-1)\n",
        "    num_filters = trial.suggest_int('num_filters', 16, 128)\n",
        "    kernel_size = trial.suggest_categorical('kernel_size', [3, 7])\n",
        "\n",
        "    model = create_model(learning_rate, num_filters, kernel_size)\n",
        "    model.fit(X_train_scaled, Y_train, epochs=8, validation_data=(X_test_scaled, Y_test), verbose=0)\n",
        "    score = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
        "    return score[1]\n",
        "\n",
        "# Run Optuna study\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=30)\n",
        "\n",
        "# Get best parameters\n",
        "best_params = study.best_params\n",
        "print(\"Best hyperparameters: \", best_params)\n",
        "\n",
        "# Train final model with best parameters\n",
        "model = create_model(best_params['learning_rate'], best_params['num_filters'], best_params['kernel_size'])\n",
        "history = model.fit(X_train_scaled, Y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=10, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "val_loss, val_accuracy = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "NDybI1TUDb7c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ResNet50"
      ],
      "metadata": {
        "id": "Xd7lGcEo2sAI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jul18GhIy8YC"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, accuracy_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize the ResNet model with transfer learning\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Add custom CNN layers\n",
        "x = base_model.output\n",
        "x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=RMSprop(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train_scaled, Y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=100, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "val_loss, val_accuracy = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate predictions for visualization\n",
        "Y_test_pred_prob = model.predict(X_test_scaled)\n",
        "Y_test_pred = np.argmax(Y_test_pred_prob, axis=1)\n",
        "\n",
        "# Convert labels for visualization\n",
        "Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=4)\n",
        "\n",
        "# Visualizations\n",
        "def plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history):\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        y_true_binary = (np.argmax(Y_test_one_hot, axis=1) == i).astype(int)\n",
        "        y_score = Y_test_pred_prob[:, i]\n",
        "        fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(Y_test, Y_test_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        precision, recall, _ = precision_recall_curve(Y_test_one_hot[:, i], Y_test_pred_prob[:, i])\n",
        "        plt.plot(recall, precision, label=f'Class {i}')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Training Curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate all visualizations\n",
        "plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history)\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(Y_test, Y_test_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(Y_test, Y_test_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "f1D4VaIF2_K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#EfficientNetB0"
      ],
      "metadata": {
        "id": "0Lc2h-2mLVjj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import numpy as np\n",
        "# import matplotlib.pyplot as plt\n",
        "# import tensorflow as tf\n",
        "# from tensorflow.keras.applications import EfficientNetB0\n",
        "# from tensorflow.keras.models import Model\n",
        "# from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "# from tensorflow.keras.optimizers import Adam\n",
        "# from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, accuracy_score, f1_score\n",
        "# import seaborn as sns\n",
        "\n",
        "# # Initialize the EfficientNetB0 model with transfer learning\n",
        "# input_shape = (224, 224, 3)\n",
        "# base_model = EfficientNetB0(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# # Add custom CNN layers\n",
        "# x = base_model.output\n",
        "# x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = MaxPooling2D((2, 2))(x)\n",
        "# x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "# x = MaxPooling2D((2, 2))(x)\n",
        "# x = GlobalAveragePooling2D()(x)\n",
        "# x = Dense(256, activation='relu')(x)\n",
        "# output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "# model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# # Freeze base model layers\n",
        "# for layer in base_model.layers:\n",
        "#     layer.trainable = False\n",
        "\n",
        "# # Compile model\n",
        "# model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "# # Train model\n",
        "# history = model.fit(X_train_scaled, Y_train,\n",
        "#                     validation_split=0.2,\n",
        "#                     epochs=70, batch_size=32, verbose=1)\n",
        "\n",
        "# # Evaluate model\n",
        "# val_loss, val_accuracy = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
        "# print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "1WJyDwwLLYoZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate predictions for visualization\n",
        "Y_test_pred_prob = model.predict(X_test_scaled)\n",
        "Y_test_pred = np.argmax(Y_test_pred_prob, axis=1)\n",
        "\n",
        "# Convert labels for visualization\n",
        "Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=4)\n",
        "\n",
        "# Visualizations\n",
        "def plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history):\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        y_true_binary = (np.argmax(Y_test_one_hot, axis=1) == i).astype(int)\n",
        "        y_score = Y_test_pred_prob[:, i]\n",
        "        fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(Y_test, Y_test_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        precision, recall, _ = precision_recall_curve(Y_test_one_hot[:, i], Y_test_pred_prob[:, i])\n",
        "        plt.plot(recall, precision, label=f'Class {i}')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Training Curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate all visualizations\n",
        "plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history)\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(Y_test, Y_test_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(Y_test, Y_test_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "jnW5DiRM6rMm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#InceptionV3"
      ],
      "metadata": {
        "id": "iAeVR_i5N7_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, accuracy_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize the InceptionV3 model with transfer learning\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Add custom CNN layers\n",
        "x = base_model.output\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train_scaled, Y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=70, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "val_loss, val_accuracy = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "3w5VvADKN67d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate predictions for visualization\n",
        "Y_test_pred_prob = model.predict(X_test_scaled)\n",
        "Y_test_pred = np.argmax(Y_test_pred_prob, axis=1)\n",
        "\n",
        "# Convert labels for visualization\n",
        "Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=4)\n",
        "\n",
        "# Visualizations\n",
        "def plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history):\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        y_true_binary = (np.argmax(Y_test_one_hot, axis=1) == i).astype(int)\n",
        "        y_score = Y_test_pred_prob[:, i]\n",
        "        fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(Y_test, Y_test_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        precision, recall, _ = precision_recall_curve(Y_test_one_hot[:, i], Y_test_pred_prob[:, i])\n",
        "        plt.plot(recall, precision, label=f'Class {i}')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Training Curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate all visualizations\n",
        "plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history)\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(Y_test, Y_test_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(Y_test, Y_test_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "BeVJAz4R6tsf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#MobileNetV2"
      ],
      "metadata": {
        "id": "bOBzx7GS4Z92"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, accuracy_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize the MobileNetV2 model with transfer learning\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = MobileNetV2(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Add custom CNN layers\n",
        "x = base_model.output\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train_scaled, Y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=70, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "val_loss, val_accuracy = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "sscPvxup4ZoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate predictions for visualization\n",
        "Y_test_pred_prob = model.predict(X_test_scaled)\n",
        "Y_test_pred = np.argmax(Y_test_pred_prob, axis=1)\n",
        "\n",
        "# Convert labels for visualization\n",
        "Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=4)\n",
        "\n",
        "# Visualizations\n",
        "def plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history):\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        y_true_binary = (np.argmax(Y_test_one_hot, axis=1) == i).astype(int)\n",
        "        y_score = Y_test_pred_prob[:, i]\n",
        "        fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(Y_test, Y_test_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        precision, recall, _ = precision_recall_curve(Y_test_one_hot[:, i], Y_test_pred_prob[:, i])\n",
        "        plt.plot(recall, precision, label=f'Class {i}')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Training Curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate all visualizations\n",
        "plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history)\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(Y_test, Y_test_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(Y_test, Y_test_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "5Fwnegy_6u0A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#VGG-19"
      ],
      "metadata": {
        "id": "GiJS2Cy04guP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.applications import VGG16\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.metrics import roc_curve, auc, precision_recall_curve, confusion_matrix, accuracy_score, f1_score\n",
        "import seaborn as sns\n",
        "\n",
        "# Initialize the VGG16 model with transfer learning\n",
        "input_shape = (224, 224, 3)\n",
        "base_model = VGG19(weights='imagenet', include_top=False, input_shape=input_shape)\n",
        "\n",
        "# Add custom CNN layers\n",
        "x = base_model.output\n",
        "x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
        "x = MaxPooling2D((2, 2))(x)\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "output = Dense(4, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=output)\n",
        "\n",
        "# Freeze base model layers\n",
        "for layer in base_model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0005),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "# Train model\n",
        "history = model.fit(X_train_scaled, Y_train,\n",
        "                    validation_split=0.2,\n",
        "                    epochs=70, batch_size=32, verbose=1)\n",
        "\n",
        "# Evaluate model\n",
        "val_loss, val_accuracy = model.evaluate(X_test_scaled, Y_test, verbose=0)\n",
        "print(f\"Validation Accuracy: {val_accuracy:.4f}\")\n"
      ],
      "metadata": {
        "id": "Yrsxn9Tk4gX3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Generate predictions for visualization\n",
        "Y_test_pred_prob = model.predict(X_test_scaled)\n",
        "Y_test_pred = np.argmax(Y_test_pred_prob, axis=1)\n",
        "\n",
        "# Convert labels for visualization\n",
        "Y_test_one_hot = tf.keras.utils.to_categorical(Y_test, num_classes=4)\n",
        "\n",
        "# Visualizations\n",
        "def plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history):\n",
        "    # ROC Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        y_true_binary = (np.argmax(Y_test_one_hot, axis=1) == i).astype(int)\n",
        "        y_score = Y_test_pred_prob[:, i]\n",
        "        fpr, tpr, _ = roc_curve(y_true_binary, y_score)\n",
        "        roc_auc = auc(fpr, tpr)\n",
        "        plt.plot(fpr, tpr, label=f'Class {i} (AUC = {roc_auc:.2f})')\n",
        "    plt.plot([0, 1], [0, 1], 'k--')\n",
        "    plt.title('ROC Curve')\n",
        "    plt.xlabel('False Positive Rate')\n",
        "    plt.ylabel('True Positive Rate')\n",
        "    plt.legend(loc='lower right')\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Confusion Matrix\n",
        "    conf_matrix = confusion_matrix(Y_test, Y_test_pred)\n",
        "    plt.figure(figsize=(10, 8))\n",
        "    sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('Actual')\n",
        "    plt.show()\n",
        "\n",
        "    # Precision-Recall Curve\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    for i in range(4):\n",
        "        precision, recall, _ = precision_recall_curve(Y_test_one_hot[:, i], Y_test_pred_prob[:, i])\n",
        "        plt.plot(recall, precision, label=f'Class {i}')\n",
        "    plt.title('Precision-Recall Curve')\n",
        "    plt.xlabel('Recall')\n",
        "    plt.ylabel('Precision')\n",
        "    plt.legend()\n",
        "    plt.grid()\n",
        "    plt.show()\n",
        "\n",
        "    # Training Curves\n",
        "    plt.figure(figsize=(12, 4))\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'], label='Training')\n",
        "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
        "    plt.title('Model Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'], label='Training')\n",
        "    plt.plot(history.history['val_loss'], label='Validation')\n",
        "    plt.title('Model Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Generate all visualizations\n",
        "plot_all_visualizations(Y_test, Y_test_one_hot, Y_test_pred, Y_test_pred_prob, history)\n",
        "\n",
        "# Print final metrics\n",
        "print(\"\\nFinal Model Performance:\")\n",
        "print(f\"Test Accuracy: {accuracy_score(Y_test, Y_test_pred):.4f}\")\n",
        "print(f\"F1 Score: {f1_score(Y_test, Y_test_pred, average='weighted'):.4f}\")\n"
      ],
      "metadata": {
        "id": "4PlTopkkLbSH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "unaPvkKLy8YD"
      },
      "outputs": [],
      "source": [
        "# model.save('efficientnetb0.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "58ledYtVy8YD"
      },
      "source": [
        "#End"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}